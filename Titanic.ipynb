{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No anomaly detection, feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_original = pd.read_csv('dataset/train.csv')\n",
    "titanic_test_original = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class CustomImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Performs specified imputing for each of Age, Cabin and Embarked features.\n",
    "    \"\"\"\n",
    "    def __init__(self, age_strategy='mean', cabin_strategy='constant', embarked_strategy='most_frequent'):\n",
    "        self.age_strategy = age_strategy\n",
    "        self.cabin_strategy = cabin_strategy\n",
    "        self.embarked_strategy = embarked_strategy\n",
    "        self.fare_strategy = 'mean'\n",
    "        self.feature_names = ['Age', 'Fare', 'Cabin', 'Embarked']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        strategies = [self.age_strategy, self.fare_strategy, self.cabin_strategy, self.embarked_strategy]\n",
    "        for feature_name, strategy in zip(self.feature_names, strategies):\n",
    "            imputer = SimpleImputer(strategy=strategy, fill_value='Empty')\n",
    "            imputed = imputer.fit_transform(X[feature_name].values.reshape(-1, 1))\n",
    "            X = X.assign(**{feature_name: imputed})\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class TicketProcessor(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Splits ticket to number and series.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder_ = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        ticket_series = X.Ticket.apply(self._get_ticket_series)\n",
    "        self.encoder_.fit(ticket_series.values.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        ticket_series = X.Ticket.apply(self._get_ticket_series)\n",
    "        encoded_series = self._get_encoded_series(ticket_series)\n",
    "        X = X.assign(Ticket_number=X.Ticket.apply(self._get_ticket_number))\n",
    "        X.drop(['Ticket'], axis=1, inplace=True)\n",
    "        return pd.concat([X, encoded_series], axis=1)\n",
    "\n",
    "    def _get_ticket_series(self, ticket):\n",
    "        splitted = ticket.split()\n",
    "        if len(splitted) > 1:\n",
    "            return '_'.join(splitted[:-1])\n",
    "        elif splitted[0] == 'LINE':\n",
    "            return 'LINE'\n",
    "        else:\n",
    "            return 'Empty'\n",
    "\n",
    "    def _get_ticket_number(self, ticket):\n",
    "        splitted = ticket.split()\n",
    "        if len(splitted) > 1:\n",
    "            return int(splitted[-1])\n",
    "        elif splitted[0] == 'LINE':\n",
    "            return 0\n",
    "        else:\n",
    "            return int(splitted[0])\n",
    "\n",
    "    def _get_encoded_series(self, ticket_series):\n",
    "        encoded_series = self.encoder_.transform(ticket_series.values.reshape(-1, 1))\n",
    "        categories = ['Ticket_series_' + cat for cat in self.encoder_.categories_[0]]\n",
    "        return pd.DataFrame(encoded_series, index=ticket_series.index, columns=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes provided features.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_names=None):\n",
    "        self.feature_names = feature_names or ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder_ = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        self.encoder_.fit(X[self.feature_names])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        encoded_features = self.encoder_.transform(X[self.feature_names])\n",
    "\n",
    "        categories = []\n",
    "        for feature, category in zip(self.feature_names, self.encoder_.categories_):\n",
    "            categories.extend(feature + '_' + str(cat) for cat in category)\n",
    "\n",
    "        X = pd.concat([\n",
    "            X, pd.DataFrame(encoded_features, columns=categories, index=X.index)\n",
    "        ], axis=1)\n",
    "\n",
    "        X.drop(self.feature_names, axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CabinEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Get some features from Cabin feature.\n",
    "    \"\"\"\n",
    "    def __init__(self, encode_by='first_letter', known=True):\n",
    "        self.encode_by = encode_by\n",
    "        self.known = known\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder_ = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        if self.encode_by == 'first_letter':\n",
    "            cabin_first_letter = X.Cabin.apply(\n",
    "                lambda x: '0' if x == 'Empty' else x[0]\n",
    "            )\n",
    "            self.encoder_.fit(cabin_first_letter.values.reshape(-1,1))\n",
    "        else:\n",
    "            self.encoder_.fit(X.Cabin.values.reshape(-1,1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.encode_by == 'first_letter':\n",
    "            cabin_first_letter = X.Cabin.apply(\n",
    "                lambda x: '0' if x == 'Empty' else x[0]\n",
    "            )\n",
    "            cabin_features = self.encoder_.transform(cabin_first_letter.values.reshape(-1,1))\n",
    "            categories = ['Cabin_first_letter_' + cat for cat in self.encoder_.categories_[0]]\n",
    "            cabin_features = pd.DataFrame(cabin_features, index=X.index, columns=categories)\n",
    "        else:\n",
    "            cabin_features = self.encoder_.transform(X.Cabin.values.reshape(-1,1))\n",
    "            categories = ['Cabin_' + cat for cat in self.encoder_.categories_[0]]\n",
    "            cabin_features = pd.DataFrame(cabin_features, index=X.index, columns=categories)\n",
    "        if self.known:\n",
    "            X = X.assign(Cabin_known=X.Cabin.apply(lambda x: 0 if x == 'Empty' else 1))\n",
    "        X.drop(['Cabin'], axis=1, inplace=True)\n",
    "        return pd.concat([X, cabin_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, first_letter=True, in_braces=True, title=True):\n",
    "        self.first_letter = first_letter\n",
    "        self.in_braces = in_braces\n",
    "        self.title = title\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.first_letter:\n",
    "            name_first_letter = X.Name.apply(lambda x: x[0])\n",
    "            self.first_letter_encoder_ = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "            self.first_letter_encoder_.fit(name_first_letter.values.reshape(-1,1))\n",
    "        if self.title:\n",
    "            name_title = X.Name.apply(lambda x: x.split()[1])\n",
    "            name_title = name_title.apply(\n",
    "                lambda x: x if name_title.value_counts()[x] > 6 else 'Other'\n",
    "            )\n",
    "            self.title_encoder_ = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "            self.title_encoder_.fit(name_title.values.reshape(-1,1))\n",
    "        if self.in_braces:\n",
    "            name_in_braces = X.Name.apply(\n",
    "                lambda x: x.split('(', 1)[1].split(')')[0] if '(' in x else 'Empty'\n",
    "            )\n",
    "            self.in_braces_encoder_ = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "            self.in_braces_encoder_.fit(name_in_braces.values.reshape(-1,1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "        if self.first_letter:\n",
    "            name_first_letter = X.Name.apply(lambda x: x[0])\n",
    "            first_letter_features = self.first_letter_encoder_.transform(name_first_letter.values.reshape(-1,1))\n",
    "            categories = ['Name_first_letter' + cat for cat in self.first_letter_encoder_.categories_[0]]\n",
    "            first_letter_features = pd.DataFrame(first_letter_features, index=X.index, columns=categories)\n",
    "            X = pd.concat([X, first_letter_features], axis=1)\n",
    "        if self.title:\n",
    "            name_title = X.Name.apply(lambda x: x.split()[1])\n",
    "            name_title = name_title.apply(\n",
    "                lambda x: x if name_title.value_counts()[x] > 6 else 'Other'\n",
    "            )\n",
    "            title_features = self.title_encoder_.transform(name_title.values.reshape(-1,1))\n",
    "            categories = ['Name_title_' + cat for cat in self.title_encoder_.categories_[0]]\n",
    "            title_features = pd.DataFrame(title_features, index=X.index, columns=categories)\n",
    "            X = pd.concat([X, title_features], axis=1)\n",
    "        if self.in_braces:\n",
    "            name_in_braces = X.Name.apply(\n",
    "                lambda x: x.split('(', 1)[1].split(')')[0] if '(' in x else 'Empty'\n",
    "            )\n",
    "            in_braces_features = self.in_braces_encoder_.transform(name_in_braces.values.reshape(-1,1))\n",
    "            categories = ['Name_in_braces_' + cat for cat in self.in_braces_encoder_.categories_[0]]\n",
    "            in_braces_features = pd.DataFrame(in_braces_features, index=X.index, columns=categories)\n",
    "            X = pd.concat([X, in_braces_features], axis=1)\n",
    "        X.drop(['Name'], axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "SEED = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('imputer', CustomImputer()),\n",
    "    ('ticket_processor', TicketProcessor()),\n",
    "    ('encoder', CustomEncoder()),\n",
    "    ('cabin_encoder', CabinEncoder()),\n",
    "    ('name_processor', NameProcessor()),\n",
    "    ('estimator', RandomForestClassifier(random_state=SEED))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=SEED)\n",
    "X = titanic_train_original.drop(['Survived'], axis=1)\n",
    "y = titanic_train_original.Survived.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'imputer__age_strategy': ['mean', 'most_frequent', 'median'],\n",
    "    'cabin_encoder__encode_by': ['first_letter', 'whole'],\n",
    "    'name_processor__first_letter': [True, False],\n",
    "    'name_processor__in_braces': [True, False],\n",
    "    'name_processor__title': [True, False],\n",
    "    \n",
    "    'estimator__n_estimators': [100, 200, 500, 1000],\n",
    "    'estimator__criterion': ['gini', 'entropy'],\n",
    "    'estimator__max_depth': np.arange(1, 16),\n",
    "    'estimator__max_features': [.33, 'sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    full_pipeline,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=4,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 23040 candidates, totalling 138240 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-40353953ce97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/titanic/venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = grid_search.cv_results_['rank_test_score']\n",
    "sort_idx = np.argsort(rank)\n",
    "best_params = np.array(grid_search.cv_results_['params'])[sort_idx]\n",
    "scores = grid_search.cv_results_['mean_test_score'][sort_idx]\n",
    "\n",
    "for i in range(5):\n",
    "    print(i+1)\n",
    "    print(scores[i])\n",
    "    print(best_params[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = [clone(full_pipeline).set_params(**params).fit(X, y) for params in best_params[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for estimator in best_estimators:\n",
    "    preds.append(estimator.predict(titanic_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submition = pd.read_csv('dataset/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
