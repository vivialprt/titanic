{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_original = pd.read_csv('titanic/train.csv')\n",
    "titanic_test_original = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = titanic_train_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['Pclass', 'Sex', 'Embarked']\n",
    "str_features = ['Name', 'Ticket', 'Cabin']\n",
    "num_features = ['Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "titanic_train['Age'] = imputer.fit_transform(titanic_train.Age.values.reshape(-1, 1))\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='Empty')\n",
    "titanic_train['Cabin'] = imputer.fit_transform(titanic_train.Cabin.values.reshape(-1, 1))\n",
    "titanic_train['Embarked'] = imputer.fit_transform(titanic_train.Embarked.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "ticket_encoder = OrdinalEncoder()\n",
    "titanic_train['Ticket_ord'] = ticket_encoder.fit_transform(titanic_train.Ticket.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_features(df, features):\n",
    "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "    encoded_features = encoder.fit_transform(df[features])\n",
    "    \n",
    "    categories = []\n",
    "    for feature, category in zip(features, encoder.categories_):\n",
    "        categories.extend(feature + '_' + str(cat) for cat in category[1:])\n",
    "        \n",
    "    return pd.DataFrame(encoded_features, columns=categories, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoded = get_encoded_features(titanic_train, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = pd.concat([\n",
    "    titanic_train,\n",
    "    cat_encoded\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Ticket_ord</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_Empty</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>cabin_known</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Empty</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>338.528620</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "      <td>0.228956</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>200.850657</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "      <td>0.420397</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>158.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>519.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.002015    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   29.699118    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  Ticket_ord    Pclass_2    Pclass_3  ...  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  ...   \n",
       "mean     0.381594   32.204208  338.528620    0.206510    0.551066  ...   \n",
       "std      0.806057   49.693429  200.850657    0.405028    0.497665  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    7.910400  158.500000    0.000000    0.000000  ...   \n",
       "50%      0.000000   14.454200  337.000000    0.000000    1.000000  ...   \n",
       "75%      0.000000   31.000000  519.500000    0.000000    1.000000  ...   \n",
       "max      6.000000  512.329200  680.000000    1.000000    1.000000  ...   \n",
       "\n",
       "       Embarked_Empty  Embarked_Q  Embarked_S  cabin_known    Pclass_2  \\\n",
       "count      891.000000  891.000000  891.000000   891.000000  891.000000   \n",
       "mean         0.002245    0.086420    0.722783     0.228956    0.206510   \n",
       "std          0.047351    0.281141    0.447876     0.420397    0.405028   \n",
       "min          0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "25%          0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "50%          0.000000    0.000000    1.000000     0.000000    0.000000   \n",
       "75%          0.000000    0.000000    1.000000     0.000000    0.000000   \n",
       "max          1.000000    1.000000    1.000000     1.000000    1.000000   \n",
       "\n",
       "         Pclass_3    Sex_male  Embarked_Empty  Embarked_Q  Embarked_S  \n",
       "count  891.000000  891.000000      891.000000  891.000000  891.000000  \n",
       "mean     0.551066    0.647587        0.002245    0.086420    0.722783  \n",
       "std      0.497665    0.477990        0.047351    0.281141    0.447876  \n",
       "min      0.000000    0.000000        0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000        0.000000    0.000000    0.000000  \n",
       "50%      1.000000    1.000000        0.000000    0.000000    1.000000  \n",
       "75%      1.000000    1.000000        0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000        1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cabin: imuting using different techniques, feature engineering, scatter with all others \n",
    "- Same with Ticket and Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin feature presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['cabin_known'] = titanic_train.Cabin.apply(\n",
    "    lambda x: 0 if x == 'Empty' else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.DataFrame(index=titanic_train.index)\n",
    "names['full_name'] = titanic_train.Name\n",
    "names['last_name'] = names.full_name.apply(lambda x: x.split()[0][:-1])\n",
    "names['title_name'] = names.full_name.apply(lambda x: x.split()[1])\n",
    "names['title_name'] = names.title_name.apply(\n",
    "    lambda x: x if names.title_name.value_counts()[x] > 6 else 'Other'\n",
    ")\n",
    "names['first_letter'] = names.full_name.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_name_Master. 0.08522056083929422\n",
      "title_name_Miss. 0.32999928131271145\n",
      "title_name_Mr. -0.5290078593371816\n",
      "title_name_Mrs. 0.3405722968353644\n",
      "title_name_Other -0.023098516517696215\n",
      "first_letter_B 0.062353755171776465\n",
      "first_letter_C 0.004447879429616431\n",
      "first_letter_D 0.056744075678256546\n",
      "first_letter_E -0.032155505992781386\n",
      "first_letter_F 0.0012720764472610147\n",
      "first_letter_G -0.06319609287597487\n",
      "first_letter_H 0.0476184738935401\n",
      "first_letter_I -0.008551007323102105\n",
      "first_letter_J -0.0065909991737594644\n",
      "first_letter_K -0.023115589520008386\n",
      "first_letter_L -0.00433668790339465\n",
      "first_letter_M 0.038435080296566324\n",
      "first_letter_N 0.05031406729446108\n",
      "first_letter_O -0.04116020555112222\n",
      "first_letter_P -0.05203836914329196\n",
      "first_letter_Q 0.06009484737835673\n",
      "first_letter_R -0.03015165698836123\n",
      "first_letter_S -0.03133910757347408\n",
      "first_letter_T 0.05738046339508236\n",
      "first_letter_U -0.026456468796962264\n",
      "first_letter_V -0.09603981150428546\n",
      "first_letter_W 0.004073395790013073\n",
      "first_letter_Y -0.0179546541663995\n",
      "first_letter_Z -0.04587552266703253\n",
      "first_letter_d 0.01604018268650749\n",
      "first_letter_v -0.03743613443241896\n"
     ]
    }
   ],
   "source": [
    "encoded_name_features = get_encoded_features(names, ['title_name', 'first_letter'])\n",
    "for feature in encoded_name_features.columns:\n",
    "    print(feature, np.corrcoef(encoded_name_features[feature], y_train)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin first letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_train['cabin_first_letter'] = titanic_train.Cabin.apply(\n",
    "    lambda x: '0' if x == 'Empty' else x[0]\n",
    ")\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "cabin_features = encoder.fit_transform(titanic_train.cabin_first_letter.values.reshape(-1,1))\n",
    "categories = ['cabin_first_letter_' + str(cat) for cat in encoder.categories_[0][1:]]\n",
    "cabin_features = pd.DataFrame(cabin_features, index=titanic_train.index, columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cabin_first_letter_A</th>\n",
       "      <th>cabin_first_letter_B</th>\n",
       "      <th>cabin_first_letter_C</th>\n",
       "      <th>cabin_first_letter_D</th>\n",
       "      <th>cabin_first_letter_E</th>\n",
       "      <th>cabin_first_letter_F</th>\n",
       "      <th>cabin_first_letter_G</th>\n",
       "      <th>cabin_first_letter_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cabin_first_letter_A  cabin_first_letter_B  cabin_first_letter_C  \\\n",
       "0                     0.0                   0.0                   0.0   \n",
       "1                     0.0                   0.0                   1.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   1.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "..                    ...                   ...                   ...   \n",
       "886                   0.0                   0.0                   0.0   \n",
       "887                   0.0                   1.0                   0.0   \n",
       "888                   0.0                   0.0                   0.0   \n",
       "889                   0.0                   0.0                   1.0   \n",
       "890                   0.0                   0.0                   0.0   \n",
       "\n",
       "     cabin_first_letter_D  cabin_first_letter_E  cabin_first_letter_F  \\\n",
       "0                     0.0                   0.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "..                    ...                   ...                   ...   \n",
       "886                   0.0                   0.0                   0.0   \n",
       "887                   0.0                   0.0                   0.0   \n",
       "888                   0.0                   0.0                   0.0   \n",
       "889                   0.0                   0.0                   0.0   \n",
       "890                   0.0                   0.0                   0.0   \n",
       "\n",
       "     cabin_first_letter_G  cabin_first_letter_T  \n",
       "0                     0.0                   0.0  \n",
       "1                     0.0                   0.0  \n",
       "2                     0.0                   0.0  \n",
       "3                     0.0                   0.0  \n",
       "4                     0.0                   0.0  \n",
       "..                    ...                   ...  \n",
       "886                   0.0                   0.0  \n",
       "887                   0.0                   0.0  \n",
       "888                   0.0                   0.0  \n",
       "889                   0.0                   0.0  \n",
       "890                   0.0                   0.0  \n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = titanic_train['Survived']\n",
    "\n",
    "X_train = pd.concat([\n",
    "    titanic_train[num_features],\n",
    "    cat_encoded,\n",
    "    encoded_name_features,\n",
    "    cabin_features\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "preds = cross_val_predict(LogisticRegression(max_iter=1000), X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[481,  68],\n",
       "       [ 90, 252]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7613293051359517"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226711560044894"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'max_depth': np.arange(1, 15),\n",
    "    'max_features': [.33, 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=1, verbose=1),\n",
    "    param_grid, verbose=1, cv=10, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1008 candidates, totalling 10080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6026 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8426 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9776 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 10080 out of 10080 | elapsed: 24.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3200            1.24s\n",
      "         2           1.3084            1.17s\n",
      "         3           1.2969            1.13s\n",
      "         4           1.2858            1.11s\n",
      "         5           1.2749            1.09s\n",
      "         6           1.2643            1.07s\n",
      "         7           1.2539            1.06s\n",
      "         8           1.2437            1.06s\n",
      "         9           1.2337            1.06s\n",
      "        10           1.2238            1.06s\n",
      "        20           1.1341            1.01s\n",
      "        30           1.0593            0.98s\n",
      "        40           0.9944            0.96s\n",
      "        50           0.9380            0.93s\n",
      "        60           0.8894            0.91s\n",
      "        70           0.8470            0.89s\n",
      "        80           0.8081            0.87s\n",
      "        90           0.7734            0.85s\n",
      "       100           0.7418            0.85s\n",
      "       200           0.5279            0.65s\n",
      "       300           0.4396            0.43s\n",
      "       400           0.3708            0.21s\n",
      "       500           0.3191            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=GradientBoostingClassifier(random_state=1, verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.001, 0.0001],\n",
       "                         'loss': ['deviance', 'exponential'],\n",
       "                         'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                         'max_features': [0.33, 'sqrt', 'log2', None],\n",
       "                         'n_estimators': [100, 250, 500]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 6,\n",
       " 'max_features': None,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3190            3.66s\n",
      "         2           1.3069            3.41s\n",
      "         3           1.2952            3.22s\n",
      "         4           1.2836            3.17s\n",
      "         5           1.2723            3.14s\n",
      "         6           1.2613            3.13s\n",
      "         7           1.2505            3.13s\n",
      "         8           1.2397            3.16s\n",
      "         9           1.2291            3.14s\n",
      "        10           1.2189            3.16s\n",
      "        20           1.1255            3.15s\n",
      "        30           1.0473            3.08s\n",
      "        40           0.9808            3.03s\n",
      "        50           0.9233            2.98s\n",
      "        60           0.8741            2.94s\n",
      "        70           0.8321            2.90s\n",
      "        80           0.7948            2.87s\n",
      "        90           0.7594            2.84s\n",
      "       100           0.7281            2.82s\n",
      "       200           0.5047            2.67s\n",
      "       300           0.4072            2.42s\n",
      "       400           0.3359            2.21s\n",
      "       500           0.2917            1.99s\n",
      "       600           0.2605            1.77s\n",
      "       700           0.2338            1.56s\n",
      "       800           0.2061            1.36s\n",
      "       900           0.1786            1.16s\n",
      "      1000           0.1558            0.97s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3202            3.36s\n",
      "         2           1.3084            3.18s\n",
      "         3           1.2969            3.28s\n",
      "         4           1.2856            3.26s\n",
      "         5           1.2746            3.25s\n",
      "         6           1.2638            3.23s\n",
      "         7           1.2532            3.19s\n",
      "         8           1.2428            3.17s\n",
      "         9           1.2326            3.14s\n",
      "        10           1.2227            3.14s\n",
      "        20           1.1331            3.04s\n",
      "        30           1.0589            3.00s\n",
      "        40           0.9958            2.96s\n",
      "        50           0.9405            2.93s\n",
      "        60           0.8914            2.92s\n",
      "        70           0.8486            2.90s\n",
      "        80           0.8108            2.89s\n",
      "        90           0.7757            2.88s\n",
      "       100           0.7440            2.88s\n",
      "       200           0.5245            2.79s\n",
      "       300           0.4213            2.59s\n",
      "       400           0.3496            2.39s\n",
      "       500           0.2986            2.15s\n",
      "       600           0.2600            1.93s\n",
      "       700           0.2320            1.69s\n",
      "       800           0.2103            1.46s\n",
      "       900           0.1919            1.24s\n",
      "      1000           0.1729            1.03s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3196            2.85s\n",
      "         2           1.3076            2.79s\n",
      "         3           1.2958            2.83s\n",
      "         4           1.2843            2.84s\n",
      "         5           1.2731            2.83s\n",
      "         6           1.2621            2.82s\n",
      "         7           1.2512            2.80s\n",
      "         8           1.2406            2.83s\n",
      "         9           1.2301            2.83s\n",
      "        10           1.2200            2.82s\n",
      "        20           1.1240            2.86s\n",
      "        30           1.0438            2.88s\n",
      "        40           0.9764            2.86s\n",
      "        50           0.9181            2.86s\n",
      "        60           0.8642            2.86s\n",
      "        70           0.8180            2.86s\n",
      "        80           0.7780            2.85s\n",
      "        90           0.7414            2.84s\n",
      "       100           0.7071            2.86s\n",
      "       200           0.4780            2.78s\n",
      "       300           0.3793            2.49s\n",
      "       400           0.3158            2.26s\n",
      "       500           0.2732            2.04s\n",
      "       600           0.2390            1.82s\n",
      "       700           0.2092            1.61s\n",
      "       800           0.1792            1.41s\n",
      "       900           0.1472            1.21s\n",
      "      1000           0.1282            1.01s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3201            3.24s\n",
      "         2           1.3085            3.04s\n",
      "         3           1.2971            3.03s\n",
      "         4           1.2857            2.99s\n",
      "         5           1.2747            3.01s\n",
      "         6           1.2639            3.00s\n",
      "         7           1.2534            2.98s\n",
      "         8           1.2429            2.97s\n",
      "         9           1.2326            2.96s\n",
      "        10           1.2226            2.95s\n",
      "        20           1.1313            2.90s\n",
      "        30           1.0541            2.87s\n",
      "        40           0.9886            2.85s\n",
      "        50           0.9308            2.85s\n",
      "        60           0.8815            2.83s\n",
      "        70           0.8388            2.81s\n",
      "        80           0.8007            2.79s\n",
      "        90           0.7662            2.78s\n",
      "       100           0.7337            2.76s\n",
      "       200           0.5222            2.63s\n",
      "       300           0.4216            2.41s\n",
      "       400           0.3533            2.19s\n",
      "       500           0.3104            1.97s\n",
      "       600           0.2765            1.75s\n",
      "       700           0.2498            1.53s\n",
      "       800           0.2274            1.32s\n",
      "       900           0.1998            1.13s\n",
      "      1000           0.1789            0.94s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3204            3.16s\n",
      "         2           1.3091            3.05s\n",
      "         3           1.2980            3.08s\n",
      "         4           1.2871            3.03s\n",
      "         5           1.2765            3.01s\n",
      "         6           1.2661            3.01s\n",
      "         7           1.2559            2.99s\n",
      "         8           1.2460            2.98s\n",
      "         9           1.2362            2.96s\n",
      "        10           1.2266            2.95s\n",
      "        20           1.1380            2.90s\n",
      "        30           1.0627            2.93s\n",
      "        40           0.9995            2.91s\n",
      "        50           0.9451            2.89s\n",
      "        60           0.8979            2.86s\n",
      "        70           0.8560            2.84s\n",
      "        80           0.8164            2.84s\n",
      "        90           0.7815            2.84s\n",
      "       100           0.7495            2.85s\n",
      "       200           0.5263            2.78s\n",
      "       300           0.4274            2.52s\n",
      "       400           0.3534            2.30s\n",
      "       500           0.3047            2.08s\n",
      "       600           0.2626            1.85s\n",
      "       700           0.2336            1.64s\n",
      "       800           0.2123            1.41s\n",
      "       900           0.1921            1.20s\n",
      "      1000           0.1714            1.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3198            3.43s\n",
      "         2           1.3076            3.19s\n",
      "         3           1.2958            3.18s\n",
      "         4           1.2842            3.16s\n",
      "         5           1.2728            3.19s\n",
      "         6           1.2616            3.22s\n",
      "         7           1.2507            3.19s\n",
      "         8           1.2400            3.16s\n",
      "         9           1.2296            3.14s\n",
      "        10           1.2194            3.12s\n",
      "        20           1.1273            3.07s\n",
      "        30           1.0502            2.98s\n",
      "        40           0.9853            2.95s\n",
      "        50           0.9291            2.93s\n",
      "        60           0.8801            2.93s\n",
      "        70           0.8372            2.92s\n",
      "        80           0.7984            2.92s\n",
      "        90           0.7601            2.93s\n",
      "       100           0.7271            2.92s\n",
      "       200           0.5212            2.72s\n",
      "       300           0.4313            2.46s\n",
      "       400           0.3674            2.26s\n",
      "       500           0.3284            2.01s\n",
      "       600           0.2910            1.78s\n",
      "       700           0.2551            1.59s\n",
      "       800           0.2235            1.39s\n",
      "       900           0.1975            1.19s\n",
      "      1000           0.1806            0.99s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3196            5.09s\n",
      "         2           1.3075            4.92s\n",
      "         3           1.2957            4.86s\n",
      "         4           1.2841            4.83s\n",
      "         5           1.2728            4.83s\n",
      "         6           1.2618            4.84s\n",
      "         7           1.2509            4.85s\n",
      "         8           1.2403            4.84s\n",
      "         9           1.2299            4.82s\n",
      "        10           1.2196            4.67s\n",
      "        20           1.1278            3.75s\n",
      "        30           1.0503            3.48s\n",
      "        40           0.9844            3.37s\n",
      "        50           0.9278            3.26s\n",
      "        60           0.8780            3.17s\n",
      "        70           0.8345            3.11s\n",
      "        80           0.7946            3.06s\n",
      "        90           0.7569            3.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       100           0.7237            3.00s\n",
      "       200           0.5224            2.73s\n",
      "       300           0.4333            2.47s\n",
      "       400           0.3642            2.28s\n",
      "       500           0.3148            2.05s\n",
      "       600           0.2759            1.83s\n",
      "       700           0.2431            1.61s\n",
      "       800           0.2192            1.40s\n",
      "       900           0.1945            1.19s\n",
      "      1000           0.1737            0.99s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3198            2.83s\n",
      "         2           1.3078            2.94s\n",
      "         3           1.2961            2.92s\n",
      "         4           1.2846            2.93s\n",
      "         5           1.2734            2.92s\n",
      "         6           1.2624            2.92s\n",
      "         7           1.2517            2.91s\n",
      "         8           1.2411            2.93s\n",
      "         9           1.2308            2.91s\n",
      "        10           1.2207            2.90s\n",
      "        20           1.1301            2.85s\n",
      "        30           1.0536            2.84s\n",
      "        40           0.9877            2.82s\n",
      "        50           0.9280            2.82s\n",
      "        60           0.8762            2.82s\n",
      "        70           0.8316            2.81s\n",
      "        80           0.7916            2.78s\n",
      "        90           0.7571            2.75s\n",
      "       100           0.7262            2.74s\n",
      "       200           0.5253            2.61s\n",
      "       300           0.4202            2.40s\n",
      "       400           0.3486            2.22s\n",
      "       500           0.3037            1.99s\n",
      "       600           0.2735            1.77s\n",
      "       700           0.2477            1.55s\n",
      "       800           0.2250            1.35s\n",
      "       900           0.2006            1.15s\n",
      "      1000           0.1748            0.96s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3202            3.37s\n",
      "         2           1.3086            3.10s\n",
      "         3           1.2973            3.03s\n",
      "         4           1.2862            2.98s\n",
      "         5           1.2754            3.01s\n",
      "         6           1.2648            3.01s\n",
      "         7           1.2542            3.00s\n",
      "         8           1.2440            3.00s\n",
      "         9           1.2339            2.99s\n",
      "        10           1.2241            2.99s\n",
      "        20           1.1346            2.92s\n",
      "        30           1.0587            2.91s\n",
      "        40           0.9935            2.89s\n",
      "        50           0.9371            2.87s\n",
      "        60           0.8866            2.85s\n",
      "        70           0.8432            2.83s\n",
      "        80           0.8043            2.82s\n",
      "        90           0.7699            2.81s\n",
      "       100           0.7370            2.81s\n",
      "       200           0.5107            2.73s\n",
      "       300           0.4083            2.50s\n",
      "       400           0.3358            2.28s\n",
      "       500           0.2902            2.04s\n",
      "       600           0.2562            1.81s\n",
      "       700           0.2243            1.60s\n",
      "       800           0.1989            1.39s\n",
      "       900           0.1770            1.19s\n",
      "      1000           0.1559            0.99s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3188            3.12s\n",
      "         2           1.3071            3.05s\n",
      "         3           1.2956            3.01s\n",
      "         4           1.2844            2.96s\n",
      "         5           1.2734            2.99s\n",
      "         6           1.2627            2.99s\n",
      "         7           1.2521            3.00s\n",
      "         8           1.2418            3.01s\n",
      "         9           1.2317            3.03s\n",
      "        10           1.2220            3.04s\n",
      "        20           1.1323            3.04s\n",
      "        30           1.0551            3.05s\n",
      "        40           0.9881            3.01s\n",
      "        50           0.9299            2.97s\n",
      "        60           0.8787            2.94s\n",
      "        70           0.8336            2.91s\n",
      "        80           0.7937            2.89s\n",
      "        90           0.7580            2.87s\n",
      "       100           0.7237            2.86s\n",
      "       200           0.5134            2.68s\n",
      "       300           0.4118            2.44s\n",
      "       400           0.3445            2.22s\n",
      "       500           0.3044            1.98s\n",
      "       600           0.2651            1.77s\n",
      "       700           0.2344            1.56s\n",
      "       800           0.2059            1.36s\n",
      "       900           0.1825            1.16s\n",
      "      1000           0.1594            0.96s\n"
     ]
    }
   ],
   "source": [
    "best_est = GradientBoostingClassifier(**grid_search.best_estimator_.get_params())\n",
    "best_est.n_estimators = 1500\n",
    "\n",
    "preds = cross_val_predict(best_est, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[488,  61],\n",
       "       [ 88, 254]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7732115677321156"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250, 500, 1000],\n",
    "    'max_depth': np.arange(1, 15),\n",
    "    'max_features': [.33, 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=1, verbose=1),\n",
    "    param_grid, verbose=1, cv=10, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 224 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=1, verbose=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                         'max_features': [0.33, 'sqrt', 'log2', None],\n",
       "                         'n_estimators': [100, 250, 500, 1000]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'max_features': 0.33, 'n_estimators': 100}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "preds = cross_val_predict(grid_search.best_estimator_, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[501,  48],\n",
       "       [ 95, 247]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755102040816327"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226711560044894"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Performs specified imputing for each of Age, Cabin and Embarked features.\n",
    "    \"\"\"\n",
    "    def __init__(self, age_strategy='mean', cabin_strategy='constant', embarked_strategy='drop_observations'):\n",
    "        self.feature_names = ['Age', 'Cabin', 'Embarked']\n",
    "        self.strategies = [age_strategy, cabin_strategy, embarked_strategy]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for feature_name, strategy in zip(self.feature_names, self.strategies):\n",
    "            if strategy == 'drop_feature':\n",
    "                X.drop([feature_name], axis=1, inplace=True)\n",
    "            elif strategy == 'drop_observations':\n",
    "                X.dropna(subset=[feature_name], inplace=True)\n",
    "            else:\n",
    "                imputer = SimpleImputer(strategy=strategy, fill_value='Empty') if strategy != 'drop' else 'drop'\n",
    "                X[feature_name] = imputer.fit_transform(X[feature_name].values.reshape(-1, 1))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicketProcessor(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Splits ticket to number and series.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X['Ticket_series'] = X.Ticket.apply(self._get_ticket_series)\n",
    "        X['Ticket_number'] = X.Ticket.apply(self._get_ticket_number)\n",
    "        encoded_series = self._get_encoded_series(X.Ticket_series)\n",
    "        X.drop(['Ticket'], axis=1, inplace=True)\n",
    "        X.drop(['Ticket_series'], axis=1, inplace=True)\n",
    "        return pd.concat([X, encoded_series], axis=1)\n",
    "\n",
    "    def _get_ticket_series(self, ticket):\n",
    "        splitted = ticket.split()\n",
    "        if len(splitted) > 1:\n",
    "            return '_'.join(splitted[:-1])\n",
    "        elif splitted[0] == 'LINE':\n",
    "            return 'LINE'\n",
    "        else:\n",
    "            return 'Empty'\n",
    "\n",
    "    def _get_ticket_number(self, ticket):\n",
    "        splitted = ticket.split()\n",
    "        if len(splitted) > 1:\n",
    "            return int(splitted[-1])\n",
    "        elif splitted[0] == 'LINE':\n",
    "            return 0\n",
    "        else:\n",
    "            return int(splitted[0])\n",
    "\n",
    "    def _get_encoded_series(self, ticket_series):\n",
    "        encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "        encoded_series = encoder.fit_transform(ticket_series.values.reshape(-1, 1))\n",
    "        categories = ['Ticket_series_' + cat for cat in encoder.categories_[0][1:]]\n",
    "        return pd.DataFrame(encoded_series, index=ticket_series.index, columns=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes provided features.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_names=None):\n",
    "        self.feature_names = feature_names or ['Pclass', 'Sex', 'Embarked']\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "        encoded_features = encoder.fit_transform(X[self.feature_names])\n",
    "\n",
    "        categories = []\n",
    "        for feature, category in zip(self.feature_names, encoder.categories_):\n",
    "            categories.extend(feature + '_' + str(cat) for cat in category[1:])\n",
    "\n",
    "        X = pd.concat([\n",
    "            X, pd.DataFrame(encoded_features, columns=categories, index=X.index)\n",
    "        ], axis=1)\n",
    "\n",
    "        X.drop(self.feature_names, axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CabinEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Get some features from Cabin feature.\n",
    "    \"\"\"\n",
    "    def __init__(self, encode_by='first_letter', known=True):\n",
    "        self.encode_by = encode_by\n",
    "        self.known = known\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "        if self.encode_by == 'first_letter':\n",
    "            cabin_first_letter = X.Cabin.apply(\n",
    "                lambda x: '0' if x == 'Empty' else x[0]\n",
    "            )\n",
    "            cabin_features = encoder.fit_transform(cabin_first_letter.values.reshape(-1,1))\n",
    "            categories = ['Cabin_first_letter_' + cat for cat in encoder.categories_[0][1:]]\n",
    "            cabin_features = pd.DataFrame(cabin_features, index=X.index, columns=categories)\n",
    "        else:\n",
    "            cabin_features = encoder.fit_transform(X.Cabin.values.reshape(-1,1))\n",
    "            categories = ['Cabin_' + cat for cat in encoder.categories_[0][1:]]\n",
    "            cabin_features = pd.DataFrame(cabin_features, index=X.index, columns=categories)\n",
    "        if self.known:\n",
    "            X['Cabin_known'] = X.Cabin.apply(lambda x: 0 if x == 'Empty' else 1)\n",
    "        X.drop(['Cabin'], axis=1, inplace=True)\n",
    "        return pd.concat([X, cabin_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, first_letter=True, in_braces=True, title=True):\n",
    "        self.first_letter = first_letter\n",
    "        self.in_braces = in_braces\n",
    "        self.title = title\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.first_letter:\n",
    "            X['Name_first_letter'] = X.Name.apply(lambda x: x[0])\n",
    "        if self.title:\n",
    "            X['Name_title'] = X.Name.apply(lambda x: x.split()[1])\n",
    "            X['Name_title'] = X.Name_title.apply(\n",
    "                lambda x: x if X.Name_title.value_counts()[x] > 6 else 'Other'\n",
    "            )\n",
    "        if self.in_braces:\n",
    "            X['Name_in_braces'] = X.Name.apply(\n",
    "                lambda x: x.split('(', 1)[1].split(')')[0] if '(' in x else 'Empty'\n",
    "            )\n",
    "        X.drop(['Name'], axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = titanic_train_original.copy()\n",
    "temp = CustomImputer().transform(temp)\n",
    "temp = TicketProcessor().transform(temp)\n",
    "temp = CustomEncoder().transform(temp)\n",
    "temp = CabinEncoder().transform(temp)\n",
    "temp = NameProcessor().transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 68)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('imputer', CustomImputer()),\n",
    "    ('ticket_processor', TicketProcessor()),\n",
    "    ('encoder', CustomEncoder()),\n",
    "    ('cabin_encoder', CabinEncoder()),\n",
    "    ('name_processor', NameProcessor()),\n",
    "    ('estimator', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(\n",
    "    titanic_train_original, test_size=100,\n",
    "    random_state=SEED, shuffle=True,\n",
    "    stratify=titanic_train_original.Survived\n",
    ")\n",
    "\n",
    "X_train = train.drop(['Survived'], axis=1)\n",
    "X_test = test.drop(['Survived'], axis=1)\n",
    "y_train = train.Survived\n",
    "y_test = test.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'imputer__age_strategy': ['mean', 'most_frequent', 'median'],\n",
    "    'imputer__embarked_strategy': ['most_frequent'],\n",
    "    'cabin_encoder__encode_by': ['first_letter', 'whole'],\n",
    "    'name_processor__first_letter': [True, False],\n",
    "    'name_processor__in_braces': [True, False],\n",
    "    'name_processor__title': [True, False],\n",
    "    \n",
    "    #'estimator__n_estimators': [100, 200, 500, 1000],\n",
    "    #'estimator__criterion': ['gini', 'entropy'],\n",
    "    #'estimator__max_depth': np.arange(1, 16),\n",
    "    #'estimator__max_features': [.33, 'sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    full_pipeline,\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=10,\n",
    "    cv=6,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 48 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "/home/ivan/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=10)]: Done 288 out of 288 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object CustomImputer(cabin_strategy=None, embarked_strategy='most_frequent'), as the constructor either does not set or modifies parameter age_strategy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-297-231b374c92ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studyspace/Hands-on Machine Learning/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object CustomImputer(cabin_strategy=None, embarked_strategy='most_frequent'), as the constructor either does not set or modifies parameter age_strategy"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "submition = pd.read_csv('titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
